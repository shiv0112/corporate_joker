{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "model = keras.models.load_model(\"colbert-trained/\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# complete code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:02.177099Z",
     "iopub.status.busy": "2021-03-29T08:43:02.176463Z",
     "iopub.status.idle": "2021-03-29T08:43:11.678132Z",
     "shell.execute_reply": "2021-03-29T08:43:11.678729Z"
    },
    "papermill": {
     "duration": 9.528184,
     "end_time": "2021-03-29T08:43:11.678854",
     "exception": false,
     "start_time": "2021-03-29T08:43:02.15067",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "# import bert_tokenization as tokenization\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras \n",
    "\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "from transformers import *\n",
    "\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re    #for regex\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019612,
     "end_time": "2021-03-29T08:43:11.7194",
     "exception": false,
     "start_time": "2021-03-29T08:43:11.699788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prep / tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.019527,
     "end_time": "2021-03-29T08:43:11.758635",
     "exception": false,
     "start_time": "2021-03-29T08:43:11.739108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 1. Read data and tokenizer\n",
    "\n",
    "Read tokenizer and data, as well as defining the maximum sequence length that will be used for the input to Bert (maximum is usually 512 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:11.804568Z",
     "iopub.status.busy": "2021-03-29T08:43:11.802828Z",
     "iopub.status.idle": "2021-03-29T08:43:11.805554Z",
     "shell.execute_reply": "2021-03-29T08:43:11.808368Z"
    },
    "papermill": {
     "duration": 0.030283,
     "end_time": "2021-03-29T08:43:11.808497",
     "exception": false,
     "start_time": "2021-03-29T08:43:11.778214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_sample_count = 1000 # 4000\n",
    "test_count = 1000\n",
    "\n",
    "MAX_SENTENCE_LENGTH = 20\n",
    "MAX_SENTENCES = 5\n",
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:11.853265Z",
     "iopub.status.busy": "2021-03-29T08:43:11.852537Z",
     "iopub.status.idle": "2021-03-29T08:43:12.526565Z",
     "shell.execute_reply": "2021-03-29T08:43:12.525978Z"
    },
    "papermill": {
     "duration": 0.698464,
     "end_time": "2021-03-29T08:43:12.526679",
     "exception": false,
     "start_time": "2021-03-29T08:43:11.828215",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!dir /kaggle/input/200k-short-texts-for-humor-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.020423,
     "end_time": "2021-03-29T08:43:12.568031",
     "exception": false,
     "start_time": "2021-03-29T08:43:12.547608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:12.616099Z",
     "iopub.status.busy": "2021-03-29T08:43:12.61558Z",
     "iopub.status.idle": "2021-03-29T08:43:13.406837Z",
     "shell.execute_reply": "2021-03-29T08:43:13.406399Z"
    },
    "papermill": {
     "duration": 0.818548,
     "end_time": "2021-03-29T08:43:13.406935",
     "exception": false,
     "start_time": "2021-03-29T08:43:12.588387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\spark\\OneDrive\\Desktop\\zero21\\bert_humour_detection\\Colbert\\Data\\dataset.csv')\n",
    "\n",
    "df_train = pd.read_csv(r'C:\\Users\\spark\\OneDrive\\Desktop\\zero21\\bert_humour_detection\\Colbert\\Data\\train.csv')\n",
    "display(df_train.head(3))\n",
    "df_train = df_train[:training_sample_count]\n",
    "\n",
    "df_test = pd.read_csv(r'C:\\Users\\spark\\OneDrive\\Desktop\\zero21\\bert_humour_detection\\Colbert\\Data\\dev.csv')\n",
    "display(df_test.head(3))\n",
    "df_test = df_test[:test_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:13.459951Z",
     "iopub.status.busy": "2021-03-29T08:43:13.455747Z",
     "iopub.status.idle": "2021-03-29T08:43:13.46956Z",
     "shell.execute_reply": "2021-03-29T08:43:13.470086Z"
    },
    "papermill": {
     "duration": 0.04181,
     "end_time": "2021-03-29T08:43:13.470207",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.428397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df_y = df_test.copy()\n",
    "del df_test['humor']\n",
    "\n",
    "df_sub = test_df_y.copy()\n",
    "\n",
    "print(len(df),len(df_train),len(df_test))\n",
    "display(df_train.head())\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:13.520664Z",
     "iopub.status.busy": "2021-03-29T08:43:13.520069Z",
     "iopub.status.idle": "2021-03-29T08:43:13.525057Z",
     "shell.execute_reply": "2021-03-29T08:43:13.524603Z"
    },
    "papermill": {
     "duration": 0.031866,
     "end_time": "2021-03-29T08:43:13.525141",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.493275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(list(df_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:13.578613Z",
     "iopub.status.busy": "2021-03-29T08:43:13.577767Z",
     "iopub.status.idle": "2021-03-29T08:43:13.583083Z",
     "shell.execute_reply": "2021-03-29T08:43:13.582502Z"
    },
    "papermill": {
     "duration": 0.034743,
     "end_time": "2021-03-29T08:43:13.583166",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.548423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_categories = list(df_train.columns[[1]])\n",
    "input_categories = list(df_train.columns[[0]])\n",
    "\n",
    "TARGET_COUNT = len(output_categories)\n",
    "\n",
    "print('\\ninput categories:\\n\\t', input_categories)\n",
    "print('\\noutput TARGET_COUNT:\\n\\t', TARGET_COUNT)\n",
    "print('\\noutput categories:\\n\\t', output_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023995,
     "end_time": "2021-03-29T08:43:13.630641",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.606646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Preprocessing functions\n",
    "\n",
    "These are some functions that will be used to preprocess the raw text data into useable Bert inputs.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:13.683343Z",
     "iopub.status.busy": "2021-03-29T08:43:13.682538Z",
     "iopub.status.idle": "2021-03-29T08:43:13.906994Z",
     "shell.execute_reply": "2021-03-29T08:43:13.906555Z"
    },
    "papermill": {
     "duration": 0.252597,
     "end_time": "2021-03-29T08:43:13.907097",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.6545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "MODEL_TYPE = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:13.960752Z",
     "iopub.status.busy": "2021-03-29T08:43:13.960068Z",
     "iopub.status.idle": "2021-03-29T08:43:14.515658Z",
     "shell.execute_reply": "2021-03-29T08:43:14.516092Z"
    },
    "papermill": {
     "duration": 0.584315,
     "end_time": "2021-03-29T08:43:14.516208",
     "exception": false,
     "start_time": "2021-03-29T08:43:13.931893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:14.581044Z",
     "iopub.status.busy": "2021-03-29T08:43:14.580438Z",
     "iopub.status.idle": "2021-03-29T08:43:14.583687Z",
     "shell.execute_reply": "2021-03-29T08:43:14.58327Z"
    },
    "papermill": {
     "duration": 0.04248,
     "end_time": "2021-03-29T08:43:14.583771",
     "exception": false,
     "start_time": "2021-03-29T08:43:14.541291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_id(str1, str2, truncation_strategy, length):\n",
    "\n",
    "    inputs = tokenizer.encode_plus(str1, str2,\n",
    "        add_special_tokens=True,\n",
    "        max_length=length,\n",
    "        truncation_strategy=truncation_strategy)\n",
    "\n",
    "    input_ids =  inputs[\"input_ids\"]\n",
    "    input_masks = [1] * len(input_ids)\n",
    "    input_segments = inputs[\"token_type_ids\"]\n",
    "    padding_length = length - len(input_ids)\n",
    "    padding_id = tokenizer.pad_token_id\n",
    "    input_ids = input_ids + ([padding_id] * padding_length)\n",
    "    input_masks = input_masks + ([0] * padding_length)\n",
    "    input_segments = input_segments + ([0] * padding_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "\n",
    "def compute_input_arrays(df, columns, tokenizer):\n",
    "    model_input = []\n",
    "    for xx in range((MAX_SENTENCES*3)+3):\n",
    "        model_input.append([])\n",
    "    \n",
    "    for _, row in tqdm(df[columns].iterrows()):\n",
    "        i = 0\n",
    "        \n",
    "        # sent\n",
    "        sentences = sent_tokenize(row.text)\n",
    "        for xx in range(MAX_SENTENCES):\n",
    "            s = sentences[xx] if xx<len(sentences) else ''\n",
    "            ids_q, masks_q, segments_q = return_id(s, None, 'longest_first', MAX_SENTENCE_LENGTH)\n",
    "            model_input[i].append(ids_q)\n",
    "            i+=1\n",
    "            model_input[i].append(masks_q)\n",
    "            i+=1\n",
    "            model_input[i].append(segments_q)\n",
    "            i+=1\n",
    "        \n",
    "        # full row\n",
    "        ids_q, masks_q, segments_q = return_id(row.text, None, 'longest_first', MAX_LENGTH)\n",
    "        model_input[i].append(ids_q)\n",
    "        i+=1\n",
    "        model_input[i].append(masks_q)\n",
    "        i+=1\n",
    "        model_input[i].append(segments_q)\n",
    "        \n",
    "    for xx in range((MAX_SENTENCES*3)+3):\n",
    "        model_input[xx] = np.asarray(model_input[xx], dtype=np.int32)\n",
    "        \n",
    "    print(model_input[0].shape)\n",
    "    return model_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:43:14.691953Z",
     "iopub.status.busy": "2021-03-29T08:43:14.691155Z",
     "iopub.status.idle": "2021-03-29T08:49:42.485601Z",
     "shell.execute_reply": "2021-03-29T08:49:42.484561Z"
    },
    "papermill": {
     "duration": 387.845343,
     "end_time": "2021-03-29T08:49:42.485726",
     "exception": false,
     "start_time": "2021-03-29T08:43:14.640383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs      = compute_input_arrays(df_train, input_categories, tokenizer)\n",
    "test_inputs = compute_input_arrays(df_test, input_categories, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:49:42.557361Z",
     "iopub.status.busy": "2021-03-29T08:49:42.556418Z",
     "iopub.status.idle": "2021-03-29T08:49:42.56174Z",
     "shell.execute_reply": "2021-03-29T08:49:42.562218Z"
    },
    "papermill": {
     "duration": 0.047335,
     "end_time": "2021-03-29T08:49:42.56236",
     "exception": false,
     "start_time": "2021-03-29T08:49:42.515025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(inputs), len(inputs[0]), len(inputs[0][0]))\n",
    "\n",
    "# check out input for 7th row\n",
    "xx = 7\n",
    "print(df_train.iloc[xx,0])\n",
    "print(sent_tokenize(df_train.iloc[xx,0]))\n",
    "inputs[0][xx], inputs[3][xx], inputs[6][xx], inputs[15][xx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:49:42.631001Z",
     "iopub.status.busy": "2021-03-29T08:49:42.630194Z",
     "iopub.status.idle": "2021-03-29T08:49:42.63394Z",
     "shell.execute_reply": "2021-03-29T08:49:42.633541Z"
    },
    "papermill": {
     "duration": 0.040866,
     "end_time": "2021-03-29T08:49:42.634025",
     "exception": false,
     "start_time": "2021-03-29T08:49:42.593159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_output_arrays(df, columns):\n",
    "    return np.asarray(df[columns])\n",
    "\n",
    "outputs = compute_output_arrays(df_train, output_categories)\n",
    "outputs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040148,
     "end_time": "2021-03-29T08:50:18.903097",
     "exception": false,
     "start_time": "2021-03-29T08:50:18.862949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Training, validation and testing\n",
    "\n",
    "Loops over the folds in gkf and trains each fold for 3 epochs --- with a learning rate of 3e-5 and batch_size of 6. A simple binary crossentropy is used as the objective-/loss-function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T08:50:19.001693Z",
     "iopub.status.busy": "2021-03-29T08:50:18.999548Z",
     "iopub.status.idle": "2021-03-29T08:50:19.013531Z",
     "shell.execute_reply": "2021-03-29T08:50:19.012967Z"
    },
    "papermill": {
     "duration": 0.073314,
     "end_time": "2021-03-29T08:50:19.013676",
     "exception": false,
     "start_time": "2021-03-29T08:50:18.940362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation Metrics\n",
    "import sklearn\n",
    "def print_evaluation_metrics(y_true, y_pred, label='', is_regression=True, label2=''):\n",
    "    print('==================', label2)\n",
    "    ### For regression\n",
    "    if is_regression:\n",
    "        print('mean_absolute_error',label,':', sklearn.metrics.mean_absolute_error(y_true, y_pred))\n",
    "        print('mean_squared_error',label,':', sklearn.metrics.mean_squared_error(y_true, y_pred))\n",
    "        print('r2 score',label,':', sklearn.metrics.r2_score(y_true, y_pred))\n",
    "        #     print('max_error',label,':', sklearn.metrics.max_error(y_true, y_pred))\n",
    "        return sklearn.metrics.mean_squared_error(y_true, y_pred)\n",
    "    else:\n",
    "        ### FOR Classification\n",
    "#         print('balanced_accuracy_score',label,':', sklearn.metrics.balanced_accuracy_score(y_true, y_pred))\n",
    "#         print('average_precision_score',label,':', sklearn.metrics.average_precision_score(y_true, y_pred))\n",
    "#         print('balanced_accuracy_score',label,':', sklearn.metrics.balanced_accuracy_score(y_true, y_pred))\n",
    "#         print('accuracy_score',label,':', sklearn.metrics.accuracy_score(y_true, y_pred))\n",
    "        print('f1_score',label,':', sklearn.metrics.f1_score(y_true, y_pred))\n",
    "        \n",
    "        matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "        print(matrix)\n",
    "        TP,TN,FP,FN = matrix[1][1],matrix[0][0],matrix[0][1],matrix[1][0]\n",
    "        Accuracy = (TP+TN)/(TP+FP+FN+TN)\n",
    "        Precision = TP/(TP+FP)\n",
    "        Recall = TP/(TP+FN)\n",
    "        F1 = 2*(Recall * Precision) / (Recall + Precision)\n",
    "        print('Acc', Accuracy, 'Prec', Precision, 'Rec', Recall, 'F1',F1)\n",
    "        return sklearn.metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "print_evaluation_metrics([1,0], [0.9,0.1], '', True)\n",
    "print_evaluation_metrics([1,0], [1,1], '', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038588,
     "end_time": "2021-03-29T08:50:19.090696",
     "exception": false,
     "start_time": "2021-03-29T08:50:19.052108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loss function selection\n",
    "Regression problem between 0 and 1, so binary_crossentropy and mean_absolute_error seem good.\n",
    "\n",
    "Here are the explanations: https://www.dlology.com/blog/how-to-choose-last-layer-activation-and-loss-function/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_inputs = inputs\n",
    "valid_outputs = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(valid_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T11:57:41.182252Z",
     "iopub.status.busy": "2021-03-29T11:57:41.181517Z",
     "iopub.status.idle": "2021-03-29T11:57:41.184593Z",
     "shell.execute_reply": "2021-03-29T11:57:41.185027Z"
    },
    "papermill": {
     "duration": 9.430336,
     "end_time": "2021-03-29T11:57:41.18514",
     "exception": false,
     "start_time": "2021-03-29T11:57:31.754804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(valid_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T11:58:00.357834Z",
     "iopub.status.busy": "2021-03-29T11:58:00.356828Z",
     "iopub.status.idle": "2021-03-29T11:58:00.379559Z",
     "shell.execute_reply": "2021-03-29T11:58:00.380362Z"
    },
    "papermill": {
     "duration": 9.363135,
     "end_time": "2021-03-29T11:58:00.380535",
     "exception": false,
     "start_time": "2021-03-29T11:57:51.0174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(valid_outputs.shape, preds.shape)\n",
    "print_evaluation_metrics(np.array(valid_outputs), np.array(preds), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 9.331535,
     "end_time": "2021-03-29T12:04:44.212433",
     "exception": false,
     "start_time": "2021-03-29T12:04:34.880898",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Binary submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T12:05:03.687138Z",
     "iopub.status.busy": "2021-03-29T12:05:03.686449Z",
     "iopub.status.idle": "2021-03-29T12:05:06.339052Z",
     "shell.execute_reply": "2021-03-29T12:05:06.337971Z"
    },
    "papermill": {
     "duration": 12.111,
     "end_time": "2021-03-29T12:05:06.339173",
     "exception": false,
     "start_time": "2021-03-29T12:04:54.228173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in np.arange(0.1, 0.99, 0.1).tolist():\n",
    "    df_sub['pred_bi'] = (test_preds > split)\n",
    "\n",
    "    print_evaluation_metrics(df_sub['humor'], df_sub['pred_bi'], '', False, 'SPLIT on '+str(split))\n",
    "\n",
    "    df_sub.to_csv('sub3.csv', index=False)\n",
    "    df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T12:05:25.599968Z",
     "iopub.status.busy": "2021-03-29T12:05:25.599118Z",
     "iopub.status.idle": "2021-03-29T12:05:25.894039Z",
     "shell.execute_reply": "2021-03-29T12:05:25.894475Z"
    },
    "papermill": {
     "duration": 10.02187,
     "end_time": "2021-03-29T12:05:25.894599",
     "exception": false,
     "start_time": "2021-03-29T12:05:15.872729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sub['pred_bi'] = (test_preds > 0.5)\n",
    "\n",
    "print_evaluation_metrics(df_sub['humor'], df_sub['pred_bi'], '', False, 'SPLIT on '+str(split))\n",
    "\n",
    "df_sub.to_csv('sub.csv', index=False)\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-29T12:05:44.469166Z",
     "iopub.status.busy": "2021-03-29T12:05:44.468382Z",
     "iopub.status.idle": "2021-03-29T12:05:44.483077Z",
     "shell.execute_reply": "2021-03-29T12:05:44.482673Z"
    },
    "papermill": {
     "duration": 9.253716,
     "end_time": "2021-03-29T12:05:44.483167",
     "exception": false,
     "start_time": "2021-03-29T12:05:35.229451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Texts that the model failed to correctly predict:')\n",
    "df_sub[df_sub['pred_bi']!=df_sub['humor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_string=[\"are you nuts inside your brain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_df=pd.DataFrame(data=input_string,columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input = compute_input_arrays(input_df, ['text'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input = model.predict(pred_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in np.arange(0.1, 0.99, 0.1).tolist():\n",
    "    input_df['pred_bi'] = (pred_input > split)\n",
    "\n",
    "    #print_evaluation_metrics(df_sub['humor'], df_sub['pred_bi'], '', False, 'SPLIT on '+str(split))\n",
    "\n",
    "    input_df.to_csv('sub3.csv', index=False)\n",
    "    input_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Binary Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_df['pred_bi'][0]==True:\n",
    "    print(\"Hahah you are funny\")\n",
    "else:\n",
    "    print(\"you are not funny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FInal; TEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    }
   ],
   "source": [
    "#load Pretrained model\n",
    "import keras\n",
    "def load_model(model_file_path):\n",
    "    model = keras.models.load_model(model_file_path)\n",
    "    return model\n",
    "\n",
    "#load tokenizer\n",
    "from transformers import BertTokenizer\n",
    "def load_tokenizer():\n",
    "    MODEL_TYPE = 'bert-base-uncased'\n",
    "    tokenizer = BertTokenizer.from_pretrained(MODEL_TYPE)\n",
    "    return tokenizer\n",
    "\n",
    "model=load_model(\"colbert-trained/\")\n",
    "tokenizer=load_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_id(str1, str2, truncation_strategy, length):\n",
    "    training_sample_count = 1000 # 4000\n",
    "    test_count = 1000\n",
    "    MAX_SENTENCE_LENGTH = 20\n",
    "    MAX_SENTENCES = 5\n",
    "    MAX_LENGTH = 100\n",
    "\n",
    "    inputs = tokenizer.encode_plus(str1, str2,\n",
    "        add_special_tokens=True,\n",
    "        max_length=length,\n",
    "        truncation_strategy=truncation_strategy)\n",
    "\n",
    "    input_ids =  inputs[\"input_ids\"]\n",
    "    input_masks = [1] * len(input_ids)\n",
    "    input_segments = inputs[\"token_type_ids\"]\n",
    "    padding_length = length - len(input_ids)\n",
    "    padding_id = tokenizer.pad_token_id\n",
    "    input_ids = input_ids + ([padding_id] * padding_length)\n",
    "    input_masks = input_masks + ([0] * padding_length)\n",
    "    input_segments = input_segments + ([0] * padding_length)\n",
    "\n",
    "    return [input_ids, input_masks, input_segments]\n",
    "\n",
    "\n",
    "def compute_input_arrays(df, columns, tokenizer):\n",
    "    training_sample_count = 1000 # 4000\n",
    "    test_count = 1000\n",
    "    MAX_SENTENCE_LENGTH = 20\n",
    "    MAX_SENTENCES = 5\n",
    "    MAX_LENGTH = 100\n",
    "    model_input = []\n",
    "    for xx in range((MAX_SENTENCES*3)+3):\n",
    "        model_input.append([])\n",
    "    \n",
    "    for _, row in tqdm(df[columns].iterrows()):\n",
    "        i = 0\n",
    "        \n",
    "        # sent\n",
    "        sentences = sent_tokenize(row.text)\n",
    "        for xx in range(MAX_SENTENCES):\n",
    "            s = sentences[xx] if xx<len(sentences) else ''\n",
    "            ids_q, masks_q, segments_q = return_id(s, None, 'longest_first', MAX_SENTENCE_LENGTH)\n",
    "            model_input[i].append(ids_q)\n",
    "            i+=1\n",
    "            model_input[i].append(masks_q)\n",
    "            i+=1\n",
    "            model_input[i].append(segments_q)\n",
    "            i+=1\n",
    "        \n",
    "        # full row\n",
    "        ids_q, masks_q, segments_q = return_id(row.text, None, 'longest_first', MAX_LENGTH)\n",
    "        model_input[i].append(ids_q)\n",
    "        i+=1\n",
    "        model_input[i].append(masks_q)\n",
    "        i+=1\n",
    "        model_input[i].append(segments_q)\n",
    "        \n",
    "    for xx in range((MAX_SENTENCES*3)+3):\n",
    "        model_input[xx] = np.asarray(model_input[xx], dtype=np.int32)\n",
    "        \n",
    "    print(model_input[0].shape)\n",
    "    return model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\spark\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "# import bert_tokenization as tokenization\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras \n",
    "\n",
    "import os\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "from transformers import *\n",
    "\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re    #for regex\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def input_for_humor_detection(input_str: list,model,tokenizer):\n",
    "    \n",
    "    \n",
    "    input_df=pd.DataFrame(data=input_str,columns=['text'])\n",
    "    pred_input = compute_input_arrays(input_df, ['text'], tokenizer)\n",
    "    pred_input = model.predict(pred_input)\n",
    "    for split in np.arange(0.1, 0.99, 0.1).tolist():\n",
    "        input_df['pred_bi'] = (pred_input > split)\n",
    "\n",
    "    #print_evaluation_metrics(df_sub['humor'], df_sub['pred_bi'], '', False, 'SPLIT on '+str(split))\n",
    "\n",
    "    #input_df.to_csv('sub3.csv', index=False)\n",
    "    print(input_df.head())\n",
    "    if input_df['pred_bi'][0]==True:\n",
    "        print(\"Hahah you are funny\")\n",
    "    else:\n",
    "        print(\"you are not funny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5696bf6956ab41c7a8841961263da325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20)\n",
      "1/1 [==============================] - 12s 12s/step\n",
      "       text  pred_bi\n",
      "0  All good    False\n",
      "you are not funny\n"
     ]
    }
   ],
   "source": [
    "input_for_humor_detection([\"All good\"],model,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_str' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43minput_str\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_str' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
